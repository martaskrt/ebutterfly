"""
Takes a list of classes and generates their output predictions for a video.

First run plot_class_embedding.py to generate the class embedding.
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
import json
import os
from sklearn.manifold import TSNE

import sys
sys.path.append('../')
from geo_prior import models
from geo_prior.paths import get_paths
import geo_prior.datasets as dt
import geo_prior.grid_predictor as grid


# this list was generated by walking through the low dimensional class embedding matrix
classes_of_interest = [2795, 2808, 2090, 2624, 1477, 743, 1500, 2754, 1622, 5717,
                       5356, 225, 26, 289, 1057, 702, 104, 103, 5300, 424, 2599,
                       35, 3295, 1628, 66, 1146, 1492, 2209, 596, 16, 1623, 326,
                       59, 22, 5787, 5227, 4687, 2659, 140, 2292, 2281, 2238, 2241,
                       2236, 2288, 2231, 2276, 243, 2313, 2210, 6, 0, 2235, 2851,
                       2778, 1405, 2906, 546, 2937, 541, 1462, 3448, 622, 130, 128,
                       2643, 1134, 24, 3256, 2837, 2785, 18, 248, 5807, 304, 4917,
                       4955, 1081, 198, 297, 287, 184, 270, 285, 97, 60, 192, 629,
                       173, 890, 1251, 778, 639, 612]

time_of_year = 0.5  # i.e. half way through the year
model_path = '../models/model_inat_2018_full_final.pth.tar'
data_dir = get_paths('inat_2018_data_dir')
op_dir = 'images/video_ims/'
if not os.path.isdir(op_dir):
    os.makedirs(op_dir)
for dd in ['dist', 'emb', 'class_name']:
    if not os.path.isdir(op_dir + dd):
        os.makedirs(op_dir + dd)
print(str(len(classes_of_interest)) + ' classes selected.\n')


# this has been precomputed by viz_class_embedding.py
if os.path.isfile('images/class_ims/all_classes.npz'):
    class_embedding = np.load('images/class_ims/all_classes.npz')
else:
    print('Error: Need to run plot_class_embedding.py first.')
    sys.exit()


# load class names
with open(data_dir + 'categories2018.json') as da:
    cls_data = json.load(da)
class_names = [cc['name'] for cc in cls_data]
class_ids = [cc['id'] for cc in cls_data]
class_dict = dict(zip(class_ids, class_names))


# load model
net_params = torch.load(model_path, map_location='cpu')
params = net_params['params']
model = models.FCNet(num_inputs=params['num_feats'], num_classes=params['num_classes'],
                     num_filts=params['num_filts'], num_users=params['num_users']).to(params['device'])

model.load_state_dict(net_params['state_dict'])
model.eval()


# load ocean mask
mask = np.load(get_paths('mask_dir') + 'ocean_mask.npy')


# grid predictor - for making dense predictions for each lon/lat location
gp = grid.GridPredictor(mask, params, mask_only_pred=True)

if not params['use_date_feats']:
    print('Trained model not using date features')


for ii in range(len(classes_of_interest)):
    print(str(ii) + '\t' + class_names[classes_of_interest[ii]])

    class_of_interest = classes_of_interest[ii]
    grid_pred = gp.dense_prediction(model, class_of_interest, time_step=time_of_year)

    op_file_name = op_dir + 'dist/' + str(ii).zfill(3) + '_' + str(class_of_interest).zfill(4) + '.png'
    plt.imsave(op_file_name, 1-grid_pred, cmap='afmhot', vmin=0, vmax=1)

    plt.close('all')
    plt.figure(0, figsize=(8,8))
    plt.scatter(class_embedding['emb'][:,0], class_embedding['emb'][:,1], s=3)
    plt.plot(class_embedding['emb'][class_of_interest,0], class_embedding['emb'][class_of_interest,1], 'ro', ms=10)
    plt.axis('off')
    plt.axis('equal')
    plt.xticks([])
    plt.yticks([])
    #plt.show()

    op_file_name = op_dir + 'emb/' + str(ii).zfill(3) + '_' + str(class_of_interest).zfill(4) + '.png'
    plt.savefig(op_file_name, transparent=True)

    plt.figure(1, figsize=(8,1))
    plt.title(class_names[class_of_interest], fontsize=24)
    plt.axis('off')
    plt.xticks([])
    plt.yticks([])
    plt.tight_layout()
    #plt.show()

    op_file_name = op_dir + 'class_name/' + str(ii).zfill(3) + '_' + str(class_of_interest).zfill(4) + '.png'
    plt.savefig(op_file_name, transparent=True)
